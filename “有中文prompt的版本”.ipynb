{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XiaoyingHeAarhus/Interact-LLM/blob/main/%E2%80%9C%E6%9C%89%E4%B8%AD%E6%96%87prompt%E7%9A%84%E7%89%88%E6%9C%AC%E2%80%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW_nvUnxDFTC",
        "outputId": "1a3fea6d-a93f-4791-80ab-9d9456411b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Interact-LLM'...\n",
            "remote: Enumerating objects: 636, done.\u001b[K\n",
            "remote: Counting objects: 100% (212/212), done.\u001b[K\n",
            "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
            "remote: Total 636 (delta 126), reused 154 (delta 100), pack-reused 424 (from 1)\u001b[K\n",
            "Receiving objects: 100% (636/636), 177.25 KiB | 1.48 MiB/s, done.\n",
            "Resolving deltas: 100% (295/295), done.\n",
            "/content/Interact-LLM\n",
            "Collecting uv\n",
            "  Downloading uv-0.9.27-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading uv-0.9.27-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.7/22.7 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uv\n",
            "Successfully installed uv-0.9.27\n",
            "\u001b[2mInstalled \u001b[1mPython 3.12.12\u001b[0m \u001b[2min 2.58s\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcpython-3.12.12-linux-x86_64-gnu\u001b[0m (python3.12)\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`\u001b[36m/root/.local/bin\u001b[39m` is not on your PATH. To use installed Python executables, run `\u001b[32mexport PATH=\"/root/.local/bin:$PATH\"\u001b[39m` or `\u001b[32muv python update-shell\u001b[39m`.\u001b[0m\n",
            "Using CPython \u001b[36m3.12.12\u001b[39m\u001b[36m\u001b[39m\n",
            "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
            "\u001b[2mResolved \u001b[1m63 packages\u001b[0m \u001b[2min 0.93ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m62 packages\u001b[0m \u001b[2min 1m 25s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m62 packages\u001b[0m \u001b[2min 493ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.5.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.1.31\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.18.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.29.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1minteract-llm\u001b[0m\u001b[2m==0.1.0 (from file:///content/Interact-LLM)\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlingua-language-detector\u001b[0m\u001b[2m==2.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlinkify-it-py\u001b[0m\u001b[2m==2.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmdit-py-plugins\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmlx\u001b[0m\u001b[2m==0.23.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmlx-lm\u001b[0m\u001b[2m==0.21.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.2.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.4.5.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.1.0.70\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.5.147\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.1.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.3.1.170\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.21.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==24.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.3.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.30.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.10.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.27.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2024.11.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==13.9.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mruff\u001b[0m\u001b[2m==0.11.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.5.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msentencepiece\u001b[0m\u001b[2m==0.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==76.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtextual\u001b[0m\u001b[2m==2.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtoml\u001b[0m\u001b[2m==0.10.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.21.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.50.0.dev0 (from git+https://github.com/huggingface/transformers@46350f5eae87ac1d168ddfdc57a0b39b64b9a029)\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.12.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1muc-micro-py\u001b[0m\u001b[2m==1.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.3.0\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 1. å…‹éš†ä»£ç \n",
        "!git clone https://github.com/XiaoyingHeAarhus/Interact-LLM.git\n",
        "%cd Interact-LLM\n",
        "\n",
        "# 2. å®‰è£… uv å’Œä¾èµ–\n",
        "!pip install uv\n",
        "# å¼ºåˆ¶ä½¿ç”¨ Python 3.12 å¹¶åˆ æ‰æ²¡ç”¨çš„ mlx (Colab é»˜è®¤æ˜¯ 3.11+)\n",
        "!uv python install 3.12\n",
        "!uv sync --python 3.12"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 1. è¿›å…¥é¡¹ç›®ç›®å½•\n",
        "%cd /content/Interact-LLM\n",
        "\n",
        "# 2. è‡ªåŠ¨åŒ–è¿è¡Œ 30 è½®çš„ Python é€»è¾‘\n",
        "# æˆ‘ä»¬é€šè¿‡å¾ªç¯è°ƒç”¨æ¥ç¡®ä¿ä»»åŠ¡çš„ç‹¬ç«‹æ€§\n",
        "for i in range(1, 31):\n",
        "    print(f\"ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ {i} è½®å®éªŒ (Total: 30)...\")\n",
        "\n",
        "    # ä½¿ç”¨ NO_COLOR=1 ä¿æŒæ—¥å¿—æ•´æ´\n",
        "    # ä½¿ç”¨ 1.5B æ¨¡å‹ä»¥ç¡®ä¿åœ¨ Colab T4 æ˜¾å­˜ä¸­ç¨³å®šè¿è¡Œ\n",
        "    # ç¡®ä¿ prompt_version å¯¹åº”ä½ é‡å‘½ååçš„ v999.0.toml\n",
        "    !NO_COLOR=1 uv run python src/scripts/alignment_drift/simulate.py \\\n",
        "        --model_name \"Qwen/Qwen2.5-1.5B-Instruct\" \\\n",
        "        --prompt_version \"999\" \\\n",
        "        --backend hf\n",
        "\n",
        "    print(f\"âœ… ç¬¬ {i} è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\")\n",
        "\n",
        "print(\"ğŸŠ æ­å–œï¼30 è½®ä¸­æ–‡å¯¹è¯æ¨¡æ‹Ÿå…¨éƒ¨è¿è¡Œå®Œæ¯•ï¼\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UORJcjWO_L_i",
        "outputId": "77258483-01e1-4ccd-80c8-62efd864db6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Interact-LLM\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 1 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 1 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 2 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 2 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 3 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 3 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 4 è½®å®éªŒ (Total: 30)...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 14, in <module>\n",
            "    from interact_llm.llm.hf_wrapper import ChatHF\n",
            "  File \"/content/Interact-LLM/src/interact_llm/llm/hf_wrapper.py\", line 8, in <module>\n",
            "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
            "  File \"<frozen importlib._bootstrap>\", line 1412, in _handle_fromlist\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1874, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1873, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1885, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/models/auto/modeling_auto.py\", line 21, in <module>\n",
            "    from .auto_factory import (\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py\", line 40, in <module>\n",
            "    from ...generation import GenerationMixin\n",
            "  File \"<frozen importlib._bootstrap>\", line 1412, in _handle_fromlist\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1873, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1885, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/generation/utils.py\", line 29, in <module>\n",
            "    from transformers.generation.candidate_generator import AssistantVocabTranslatorCache\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/generation/candidate_generator.py\", line 30, in <module>\n",
            "    from ..pytorch_utils import isin_mps_friendly\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py\", line 49, in <module>\n",
            "    from torch.distributed.tensor.parallel import (\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/__init__.py\", line 2, in <module>\n",
            "    from torch.distributed.tensor.parallel.api import parallelize_module\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/api.py\", line 9, in <module>\n",
            "    from torch.distributed.tensor.parallel._utils import _validate_tp_mesh_dim\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/_utils.py\", line 11, in <module>\n",
            "    from torch._dynamo.external_utils import is_compiling as is_torchdynamo_compiling\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/_dynamo/__init__.py\", line 3, in <module>\n",
            "    from . import convert_frame, eval_frame, resume_execution\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 33, in <module>\n",
            "    from torch._dynamo.symbolic_convert import TensorifyState\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 27, in <module>\n",
            "    from torch._dynamo.exc import TensorifyScalarRestartAnalysis\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/_dynamo/exc.py\", line 11, in <module>\n",
            "    from .utils import counters\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py\", line 66, in <module>\n",
            "    import torch.fx.experimental.symbolic_shapes\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 64, in <module>\n",
            "    from torch.fx.experimental.recording import (\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/fx/experimental/recording.py\", line 345, in <module>\n",
            "    @dataclass\n",
            "     ^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/dataclasses.py\", line 1275, in dataclass\n",
            "    return wrap(cls)\n",
            "           ^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/dataclasses.py\", line 1265, in wrap\n",
            "    return _process_class(cls, init, repr, eq, order, unsafe_hash,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/dataclasses.py\", line 1063, in _process_class\n",
            "    _init_fn(all_init_fields,\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/dataclasses.py\", line 588, in _init_fn\n",
            "    locals = {f'__dataclass_type_{f.name}__': f.type for f in fields}\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "âœ… ç¬¬ 4 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 5 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 5 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 6 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 6 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 7 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 7 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 8 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 8 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 9 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 9 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 10 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 10 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 11 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 11 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 12 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 12 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 13 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 13 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 14 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 14 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 15 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 15 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 16 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 16 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 17 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 17 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 18 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 18 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 19 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 19 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 20 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 20 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 21 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 21 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 22 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 22 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 23 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 23 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 24 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 24 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 25 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 25 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 26 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "tokenizer_config.json: 7.30kB [00:00, 37.7MB/s]\n",
            "vocab.json: 2.78MB [00:00, 70.6MB/s]\n",
            "merges.txt: 1.67MB [00:00, 141MB/s]\n",
            "tokenizer.json: 7.03MB [00:00, 187MB/s]\n",
            "config.json: 100% 660/660 [00:00<00:00, 5.03MB/s]\n",
            "model.safetensors:   2% 73.4M/3.09G [00:30<20:35, 2.44MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 109, in load_model_backend\n",
            "    model.load()\n",
            "  File \"/content/Interact-LLM/src/interact_llm/llm/hf_wrapper.py\", line 44, in load\n",
            "    self.model = AutoModelForCausalLM.from_pretrained(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 273, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 3998, in from_pretrained\n",
            "    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/hub.py\", line 342, in cached_file\n",
            "    resolved_file = hf_hub_download(\n",
            "                    ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 862, in hf_hub_download\n",
            "    return _hf_hub_download_to_cache_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 1011, in _hf_hub_download_to_cache_dir\n",
            "    _download_to_tmp_and_move(\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 1547, in _download_to_tmp_and_move\n",
            "    http_get(\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 454, in http_get\n",
            "    for chunk in r.iter_content(chunk_size=constants.DOWNLOAD_CHUNK_SIZE):\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/requests/models.py\", line 820, in generate\n",
            "    yield from self.raw.stream(chunk_size, decode_content=True)\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/urllib3/response.py\", line 1066, in stream\n",
            "    data = self.read(amt=amt, decode_content=decode_content)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/urllib3/response.py\", line 955, in read\n",
            "    data = self._raw_read(amt)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/urllib3/response.py\", line 879, in _raw_read\n",
            "    data = self._fp_read(amt, read1=read1) if not fp_closed else b\"\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/urllib3/response.py\", line 862, in _fp_read\n",
            "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/http/client.py\", line 479, in read\n",
            "    s = self.fp.read(amt)\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/socket.py\", line 720, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/ssl.py\", line 1251, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/ssl.py\", line 1103, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "âœ… ç¬¬ 26 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 27 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "model.safetensors: 100% 3.09G/3.09G [02:28<00:00, 20.2MB/s]\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "generation_config.json: 100% 242/242 [00:00<00:00, 1.38MB/s]\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            " 22% 2/9 [00:09<00:33,  4.81s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Interact-LLM\n",
        "\n",
        "for i in range(1, 31):\n",
        "    print(f\"ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ {i} è½®å®éªŒ...\")\n",
        "    # æ³¨æ„è¿™é‡Œä½¿ç”¨çš„æ˜¯ name å®šä¹‰çš„ç®€ç§° qwen25_15b\n",
        "    !NO_COLOR=1 uv run python src/scripts/alignment_drift/simulate.py \\\n",
        "        --model_name \"qwen25_15b\" \\\n",
        "        --prompt_version \"999\" \\\n",
        "        --backend hf\n",
        "    print(f\"âœ… ç¬¬ {i} è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\")\n",
        "\n",
        "print(\"ğŸŠ æ­å–œï¼30 è½®ä¸­æ–‡å¯¹è¯æ¨¡æ‹Ÿå…¨éƒ¨è¿è¡Œå®Œæ¯•ï¼\")"
      ],
      "metadata": {
        "id": "8Ik6G47gA2GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6xCP-0yDRVa",
        "outputId": "fc92241d-94c5-4e0a-9be6-8503026e41b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Running simulation run 1 out of 30\n",
            "tokenizer_config.json: 7.30kB [00:00, 25.3MB/s]\n",
            "vocab.json: 2.78MB [00:00, 101MB/s]\n",
            "merges.txt: 1.67MB [00:00, 102MB/s]\n",
            "tokenizer.json: 7.03MB [00:00, 136MB/s]\n",
            "config.json: 100% 663/663 [00:00<00:00, 4.11MB/s]\n",
            "model.safetensors.index.json: 27.8kB [00:00, 110MB/s]\n",
            "Downloading shards:   0% 0/4 [00:00<?, ?it/s]\n",
            "model-00001-of-00004.safetensors:   0% 0.00/3.95G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 10.5M/3.95G [00:01<08:40, 7.57MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   1% 31.5M/3.95G [00:01<02:35, 25.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   1% 52.4M/3.95G [00:01<01:28, 44.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   2% 73.4M/3.95G [00:01<00:59, 64.7MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   2% 94.4M/3.95G [00:01<00:45, 84.4MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   3% 115M/3.95G [00:02<00:37, 103MB/s]  \u001b[A\n",
            "model-00001-of-00004.safetensors:   3% 136M/3.95G [00:02<00:33, 114MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   4% 157M/3.95G [00:02<00:30, 124MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   5% 178M/3.95G [00:02<00:27, 137MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   5% 199M/3.95G [00:02<00:31, 119MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   6% 220M/3.95G [00:02<00:28, 132MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   6% 241M/3.95G [00:02<00:26, 142MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   7% 262M/3.95G [00:03<00:24, 150MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   7% 283M/3.95G [00:03<00:23, 156MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   8% 304M/3.95G [00:03<00:22, 161MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   8% 325M/3.95G [00:03<00:22, 160MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   9% 346M/3.95G [00:03<00:23, 153MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   9% 367M/3.95G [00:03<00:22, 159MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  10% 388M/3.95G [00:05<02:04, 28.6MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  10% 409M/3.95G [00:05<01:32, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  11% 430M/3.95G [00:06<01:10, 50.0MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  11% 451M/3.95G [00:06<00:55, 63.5MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 472M/3.95G [00:06<00:46, 74.7MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 493M/3.95G [00:06<00:38, 90.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  13% 514M/3.95G [00:06<00:32, 105MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:  14% 535M/3.95G [00:06<00:29, 117MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  14% 556M/3.95G [00:06<00:26, 128MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  15% 577M/3.95G [00:06<00:24, 139MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  15% 598M/3.95G [00:07<00:22, 147MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  16% 619M/3.95G [00:07<00:21, 153MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  16% 640M/3.95G [00:11<03:19, 16.6MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  17% 661M/3.95G [00:14<04:53, 11.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  17% 682M/3.95G [00:14<03:29, 15.5MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  18% 703M/3.95G [00:17<04:56, 10.9MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  18% 713M/3.95G [00:18<05:00, 10.7MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  18% 724M/3.95G [00:19<04:46, 11.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19% 734M/3.95G [00:19<03:52, 13.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19% 744M/3.95G [00:19<03:11, 16.7MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19% 755M/3.95G [00:20<02:49, 18.9MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19% 765M/3.95G [00:21<03:24, 15.6MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  20% 776M/3.95G [00:22<04:06, 12.9MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  20% 786M/3.95G [00:23<04:27, 11.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  20% 797M/3.95G [00:25<06:36, 7.95MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  20% 807M/3.95G [00:27<06:58, 7.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  21% 818M/3.95G [00:27<05:23, 9.66MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  21% 839M/3.95G [00:28<03:47, 13.6MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  22% 849M/3.95G [00:31<05:43, 9.03MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  22% 860M/3.95G [00:35<10:31, 4.88MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  22% 870M/3.95G [00:38<10:36, 4.83MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  22% 881M/3.95G [00:40<10:08, 5.03MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  23% 891M/3.95G [00:41<08:39, 5.88MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  23% 902M/3.95G [00:41<06:45, 7.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  23% 912M/3.95G [00:43<06:58, 7.24MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  23% 923M/3.95G [00:43<06:04, 8.30MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24% 933M/3.95G [00:44<05:00, 10.0MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24% 944M/3.95G [00:44<04:07, 12.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24% 954M/3.95G [00:45<03:24, 14.6MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24% 965M/3.95G [00:46<03:30, 14.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  25% 975M/3.95G [00:47<04:36, 10.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  25% 986M/3.95G [00:50<07:05, 6.95MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  25% 996M/3.95G [00:52<07:38, 6.44MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  26% 1.01G/3.95G [01:02<19:33, 2.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  26% 1.02G/3.95G [01:03<15:08, 3.22MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  26% 1.03G/3.95G [01:04<11:29, 4.23MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  26% 1.04G/3.95G [01:05<09:46, 4.96MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27% 1.05G/3.95G [01:09<12:58, 3.72MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27% 1.06G/3.95G [01:11<11:56, 4.03MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27% 1.07G/3.95G [01:16<14:35, 3.29MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27% 1.08G/3.95G [01:20<15:43, 3.04MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28% 1.09G/3.95G [01:24<16:05, 2.96MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28% 1.10G/3.95G [01:24<11:25, 4.15MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28% 1.11G/3.95G [01:24<08:08, 5.80MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28% 1.12G/3.95G [01:24<05:51, 8.04MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  29% 1.14G/3.95G [01:24<03:15, 14.3MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  30% 1.16G/3.95G [01:25<02:03, 22.5MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  30% 1.18G/3.95G [01:25<01:39, 27.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  31% 1.21G/3.95G [01:25<01:11, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  31% 1.23G/3.95G [01:25<00:53, 51.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  32% 1.25G/3.95G [01:26<01:01, 44.0MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  32% 1.27G/3.95G [01:26<00:46, 57.3MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  33% 1.29G/3.95G [01:26<00:36, 72.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  33% 1.31G/3.95G [01:26<00:30, 87.3MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  34% 1.33G/3.95G [01:27<00:38, 67.6MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  34% 1.35G/3.95G [01:27<00:32, 80.9MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  35% 1.37G/3.95G [01:27<00:26, 95.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  35% 1.39G/3.95G [01:28<00:40, 63.3MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  36% 1.42G/3.95G [01:28<00:32, 78.0MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  36% 1.44G/3.95G [01:28<00:26, 93.3MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  37% 1.46G/3.95G [01:28<00:35, 70.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  37% 1.48G/3.95G [01:28<00:29, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  38% 1.50G/3.95G [01:29<00:40, 59.7MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  39% 1.52G/3.95G [01:30<00:49, 49.0MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  39% 1.53G/3.95G [01:30<00:45, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  39% 1.55G/3.95G [01:30<00:34, 68.6MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  40% 1.57G/3.95G [01:30<00:32, 72.0MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  40% 1.59G/3.95G [01:30<00:26, 87.7MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  41% 1.61G/3.95G [01:30<00:22, 103MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:  41% 1.64G/3.95G [01:31<00:19, 117MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42% 1.66G/3.95G [01:31<00:20, 113MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  43% 1.68G/3.95G [01:31<00:18, 126MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  43% 1.70G/3.95G [01:31<00:16, 137MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  44% 1.72G/3.95G [01:31<00:15, 145MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  44% 1.74G/3.95G [01:31<00:14, 151MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  45% 1.76G/3.95G [01:31<00:14, 156MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  45% 1.78G/3.95G [01:31<00:13, 159MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  46% 1.80G/3.95G [01:32<00:13, 156MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  46% 1.82G/3.95G [01:32<00:13, 159MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  47% 1.85G/3.95G [01:32<00:13, 160MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  47% 1.87G/3.95G [01:32<00:12, 161MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  48% 1.89G/3.95G [01:32<00:12, 160MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  48% 1.91G/3.95G [01:32<00:12, 160MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  49% 1.93G/3.95G [01:34<00:48, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  49% 1.95G/3.95G [01:34<00:37, 53.4MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  50% 1.97G/3.95G [01:36<01:30, 21.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  50% 1.99G/3.95G [01:37<01:35, 20.5MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  51% 2.00G/3.95G [01:39<02:31, 12.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  51% 2.02G/3.95G [01:44<03:55, 8.17MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  52% 2.04G/3.95G [01:44<02:41, 11.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  52% 2.06G/3.95G [01:46<03:04, 10.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  53% 2.08G/3.95G [01:46<02:03, 15.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  53% 2.10G/3.95G [01:46<01:24, 21.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  54% 2.12G/3.95G [01:47<01:31, 20.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  54% 2.14G/3.95G [01:47<01:05, 27.6MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  55% 2.16G/3.95G [01:47<00:47, 37.3MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  55% 2.18G/3.95G [01:47<00:35, 49.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  56% 2.20G/3.95G [01:48<00:27, 62.7MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  56% 2.22G/3.95G [01:48<00:22, 77.7MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  57% 2.24G/3.95G [01:48<00:18, 92.3MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  57% 2.26G/3.95G [01:48<00:15, 108MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:  58% 2.29G/3.95G [01:48<00:13, 121MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  58% 2.31G/3.95G [01:48<00:12, 131MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  59% 2.33G/3.95G [01:48<00:11, 141MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  60% 2.35G/3.95G [01:48<00:10, 147MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  60% 2.37G/3.95G [01:49<00:10, 153MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  61% 2.39G/3.95G [01:49<00:09, 158MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  61% 2.41G/3.95G [01:49<00:09, 163MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  62% 2.43G/3.95G [01:49<00:10, 147MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  62% 2.45G/3.95G [01:49<00:12, 116MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63% 2.47G/3.95G [01:49<00:13, 110MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63% 2.50G/3.95G [01:50<00:14, 101MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  64% 2.52G/3.95G [01:50<00:12, 116MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  64% 2.54G/3.95G [01:50<00:11, 122MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  65% 2.56G/3.95G [01:50<00:10, 133MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  65% 2.58G/3.95G [01:50<00:09, 143MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  66% 2.60G/3.95G [01:50<00:09, 147MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  66% 2.62G/3.95G [01:51<00:08, 152MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  67% 2.64G/3.95G [01:51<00:08, 157MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68% 2.66G/3.95G [01:51<00:08, 160MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68% 2.68G/3.95G [01:51<00:07, 161MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  69% 2.71G/3.95G [01:51<00:07, 164MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  69% 2.73G/3.95G [01:51<00:07, 166MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  70% 2.75G/3.95G [01:51<00:08, 137MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  70% 2.77G/3.95G [01:51<00:08, 147MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71% 2.79G/3.95G [01:52<00:07, 153MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71% 2.81G/3.95G [01:52<00:07, 158MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  72% 2.83G/3.95G [01:52<00:06, 161MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  72% 2.85G/3.95G [01:52<00:06, 162MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  73% 2.87G/3.95G [01:55<00:43, 24.5MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  73% 2.89G/3.95G [01:55<00:31, 33.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74% 2.92G/3.95G [01:55<00:24, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74% 2.94G/3.95G [01:55<00:20, 49.6MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  75% 2.96G/3.95G [01:55<00:18, 53.0MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  75% 2.98G/3.95G [01:56<00:14, 66.4MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  76% 3.00G/3.95G [01:56<00:11, 81.4MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  77% 3.02G/3.95G [01:56<00:09, 95.7MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  77% 3.04G/3.95G [01:56<00:08, 109MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:  78% 3.06G/3.95G [01:56<00:07, 122MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  78% 3.08G/3.95G [01:56<00:06, 132MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  79% 3.10G/3.95G [01:56<00:05, 143MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  79% 3.12G/3.95G [01:56<00:05, 152MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  80% 3.15G/3.95G [01:57<00:05, 157MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  80% 3.17G/3.95G [01:57<00:04, 162MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  81% 3.19G/3.95G [01:57<00:04, 162MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  81% 3.21G/3.95G [01:57<00:04, 151MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82% 3.23G/3.95G [01:57<00:04, 156MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82% 3.25G/3.95G [01:57<00:04, 159MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  83% 3.27G/3.95G [01:57<00:04, 158MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  83% 3.29G/3.95G [01:57<00:04, 158MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  84% 3.31G/3.95G [02:01<00:31, 20.0MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  85% 3.33G/3.95G [02:01<00:22, 27.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  85% 3.36G/3.95G [02:01<00:16, 36.0MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  86% 3.38G/3.95G [02:01<00:12, 47.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  86% 3.40G/3.95G [02:01<00:09, 57.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  87% 3.42G/3.95G [02:01<00:07, 69.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  87% 3.44G/3.95G [02:02<00:06, 75.5MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  88% 3.46G/3.95G [02:02<00:05, 90.7MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  88% 3.48G/3.95G [02:02<00:04, 102MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:  89% 3.50G/3.95G [02:02<00:03, 116MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  89% 3.52G/3.95G [02:02<00:03, 130MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  90% 3.54G/3.95G [02:02<00:02, 140MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  90% 3.57G/3.95G [02:02<00:02, 149MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  91% 3.59G/3.95G [02:02<00:02, 155MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  91% 3.61G/3.95G [02:03<00:02, 116MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  92% 3.63G/3.95G [02:03<00:02, 129MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  92% 3.65G/3.95G [02:03<00:02, 139MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  93% 3.67G/3.95G [02:03<00:01, 147MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  94% 3.69G/3.95G [02:07<00:14, 17.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  94% 3.71G/3.95G [02:07<00:09, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  95% 3.73G/3.95G [02:07<00:06, 31.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  95% 3.75G/3.95G [02:07<00:04, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96% 3.77G/3.95G [02:07<00:03, 54.5MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96% 3.80G/3.95G [02:07<00:02, 67.9MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  97% 3.82G/3.95G [02:08<00:01, 70.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  97% 3.84G/3.95G [02:08<00:02, 51.3MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  98% 3.85G/3.95G [02:09<00:01, 52.5MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  98% 3.87G/3.95G [02:09<00:01, 67.7MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  99% 3.89G/3.95G [02:09<00:00, 72.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  99% 3.91G/3.95G [02:09<00:00, 86.0MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors: 100% 3.93G/3.95G [02:09<00:00, 95.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors: 100% 3.95G/3.95G [02:09<00:00, 30.4MB/s]\n",
            "Downloading shards:  25% 1/4 [02:10<06:31, 130.46s/it]\n",
            "model-00002-of-00004.safetensors:   0% 0.00/3.86G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   0% 10.5M/3.86G [00:01<08:19, 7.72MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   1% 31.5M/3.86G [00:01<02:26, 26.1MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   1% 52.4M/3.86G [00:01<01:22, 46.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   2% 73.4M/3.86G [00:01<00:56, 67.1MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   2% 94.4M/3.86G [00:01<00:43, 86.2MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   3% 115M/3.86G [00:02<00:38, 96.6MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:   4% 136M/3.86G [00:02<00:36, 101MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:   4% 157M/3.86G [00:02<00:39, 94.7MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   5% 178M/3.86G [00:02<00:33, 110MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:   5% 199M/3.86G [00:02<00:29, 123MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   6% 220M/3.86G [00:02<00:27, 135MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   6% 241M/3.86G [00:02<00:25, 141MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   7% 262M/3.86G [00:03<00:25, 142MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   7% 283M/3.86G [00:03<00:24, 149MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   8% 304M/3.86G [00:03<00:23, 153MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   8% 325M/3.86G [00:03<00:22, 157MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   9% 346M/3.86G [00:03<00:21, 160MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   9% 367M/3.86G [00:03<00:21, 160MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  10% 388M/3.86G [00:03<00:21, 161MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  11% 409M/3.86G [00:04<00:31, 110MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  11% 430M/3.86G [00:07<03:21, 17.0MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  11% 440M/3.86G [00:09<03:57, 14.4MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  12% 461M/3.86G [00:09<02:44, 20.7MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  12% 472M/3.86G [00:09<02:43, 20.8MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  13% 493M/3.86G [00:09<01:51, 30.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  13% 514M/3.86G [00:10<01:20, 41.7MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  14% 535M/3.86G [00:10<01:00, 55.1MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  14% 556M/3.86G [00:10<00:47, 69.8MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  15% 577M/3.86G [00:10<00:38, 84.5MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  15% 598M/3.86G [00:10<00:32, 99.8MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  16% 619M/3.86G [00:10<00:28, 113MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  17% 640M/3.86G [00:10<00:25, 125MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  17% 661M/3.86G [00:10<00:24, 131MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  18% 682M/3.86G [00:11<00:22, 139MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  18% 703M/3.86G [00:11<00:21, 147MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  19% 724M/3.86G [00:11<00:21, 147MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  19% 744M/3.86G [00:11<00:20, 149MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  20% 765M/3.86G [00:11<00:20, 155MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  20% 786M/3.86G [00:11<00:19, 160MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  21% 807M/3.86G [00:11<00:23, 128MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  21% 828M/3.86G [00:15<02:46, 18.2MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  22% 849M/3.86G [00:15<02:00, 24.9MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  23% 870M/3.86G [00:15<01:30, 33.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  23% 891M/3.86G [00:15<01:16, 38.9MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  24% 912M/3.86G [00:16<01:04, 45.4MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  24% 933M/3.86G [00:16<01:10, 41.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  24% 944M/3.86G [00:16<01:04, 45.0MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  25% 954M/3.86G [00:17<01:04, 45.2MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  25% 975M/3.86G [00:17<00:46, 61.6MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26% 996M/3.86G [00:17<00:36, 79.2MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26% 1.02G/3.86G [00:17<00:29, 95.6MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  27% 1.04G/3.86G [00:17<00:25, 111MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  27% 1.06G/3.86G [00:17<00:22, 124MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  28% 1.08G/3.86G [00:17<00:20, 135MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  28% 1.10G/3.86G [00:18<00:20, 135MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  29% 1.12G/3.86G [00:18<00:19, 142MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  30% 1.14G/3.86G [00:18<00:18, 148MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  30% 1.16G/3.86G [00:18<00:17, 155MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  31% 1.18G/3.86G [00:18<00:17, 156MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  31% 1.21G/3.86G [00:18<00:16, 158MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  32% 1.23G/3.86G [00:18<00:16, 162MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  32% 1.25G/3.86G [00:19<00:16, 163MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  33% 1.27G/3.86G [00:19<00:15, 163MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  33% 1.29G/3.86G [00:19<00:15, 164MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  34% 1.31G/3.86G [00:19<00:15, 166MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  34% 1.33G/3.86G [00:19<00:15, 167MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  35% 1.35G/3.86G [00:19<00:21, 119MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  36% 1.37G/3.86G [00:20<00:26, 94.0MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  36% 1.39G/3.86G [00:20<00:22, 109MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  37% 1.42G/3.86G [00:20<00:39, 61.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  37% 1.44G/3.86G [00:21<00:32, 75.6MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  38% 1.46G/3.86G [00:21<00:26, 90.4MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  38% 1.48G/3.86G [00:21<00:23, 102MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  39% 1.50G/3.86G [00:21<00:20, 114MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  39% 1.52G/3.86G [00:21<00:18, 127MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  40% 1.54G/3.86G [00:21<00:17, 135MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  40% 1.56G/3.86G [00:21<00:16, 141MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  41% 1.58G/3.86G [00:22<00:15, 146MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  42% 1.60G/3.86G [00:22<00:14, 154MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  42% 1.63G/3.86G [00:25<02:00, 18.6MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  43% 1.65G/3.86G [00:25<01:27, 25.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  43% 1.67G/3.86G [00:25<01:04, 33.9MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  44% 1.69G/3.86G [00:25<00:48, 44.5MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  44% 1.71G/3.86G [00:26<00:38, 56.2MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  45% 1.73G/3.86G [00:26<00:30, 69.5MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  45% 1.75G/3.86G [00:26<00:25, 83.6MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  46% 1.77G/3.86G [00:26<00:21, 97.5MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  46% 1.79G/3.86G [00:26<00:18, 112MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  47% 1.81G/3.86G [00:26<00:23, 86.0MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  47% 1.84G/3.86G [00:27<00:20, 100MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  48% 1.86G/3.86G [00:27<00:23, 84.5MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  49% 1.88G/3.86G [00:28<00:38, 51.1MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  49% 1.90G/3.86G [00:28<00:30, 64.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  50% 1.92G/3.86G [00:28<00:24, 78.5MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  50% 1.94G/3.86G [00:28<00:20, 93.1MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  51% 1.96G/3.86G [00:28<00:17, 107MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  51% 1.98G/3.86G [00:28<00:15, 119MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  52% 2.00G/3.86G [00:29<00:19, 95.4MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  52% 2.02G/3.86G [00:29<00:17, 108MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  53% 2.04G/3.86G [00:29<00:20, 88.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  53% 2.07G/3.86G [00:30<00:24, 72.6MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  54% 2.08G/3.86G [00:30<00:23, 76.2MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  54% 2.10G/3.86G [00:30<00:18, 93.2MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  55% 2.12G/3.86G [00:30<00:16, 107MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  55% 2.14G/3.86G [00:30<00:14, 121MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  56% 2.16G/3.86G [00:30<00:12, 132MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  56% 2.18G/3.86G [00:30<00:12, 139MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  57% 2.20G/3.86G [00:30<00:11, 146MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  58% 2.22G/3.86G [00:31<00:10, 149MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  58% 2.24G/3.86G [00:31<00:10, 151MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  59% 2.26G/3.86G [00:31<00:10, 152MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  59% 2.29G/3.86G [00:31<00:09, 158MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  60% 2.31G/3.86G [00:31<00:09, 159MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  60% 2.33G/3.86G [00:31<00:09, 161MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  61% 2.35G/3.86G [00:31<00:09, 164MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  61% 2.37G/3.86G [00:32<00:09, 164MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  62% 2.39G/3.86G [00:32<00:09, 163MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  62% 2.41G/3.86G [00:35<01:22, 17.6MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  63% 2.43G/3.86G [00:35<00:59, 24.0MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  63% 2.45G/3.86G [00:36<00:44, 32.0MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  64% 2.47G/3.86G [00:36<00:40, 34.2MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  65% 2.50G/3.86G [00:36<00:30, 44.9MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  65% 2.52G/3.86G [00:36<00:23, 57.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  66% 2.54G/3.86G [00:36<00:18, 70.5MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  66% 2.56G/3.86G [00:37<00:15, 84.5MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  67% 2.58G/3.86G [00:37<00:12, 99.0MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  67% 2.60G/3.86G [00:37<00:11, 112MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  68% 2.62G/3.86G [00:37<00:09, 125MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  68% 2.64G/3.86G [00:37<00:09, 135MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  69% 2.66G/3.86G [00:37<00:08, 143MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  69% 2.68G/3.86G [00:37<00:07, 150MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  70% 2.71G/3.86G [00:38<00:07, 154MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  71% 2.73G/3.86G [00:38<00:07, 159MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  71% 2.75G/3.86G [00:38<00:09, 120MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72% 2.77G/3.86G [00:38<00:08, 131MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72% 2.79G/3.86G [00:41<00:58, 18.4MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  73% 2.81G/3.86G [00:42<00:41, 25.1MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  73% 2.83G/3.86G [00:42<00:30, 33.7MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  74% 2.85G/3.86G [00:42<00:22, 44.4MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  74% 2.87G/3.86G [00:42<00:21, 45.2MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  75% 2.89G/3.86G [00:44<00:44, 21.9MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  75% 2.90G/3.86G [00:46<01:04, 14.9MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76% 2.93G/3.86G [00:46<00:43, 21.4MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76% 2.94G/3.86G [00:51<01:49, 8.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76% 2.95G/3.86G [00:51<01:27, 10.5MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  77% 2.97G/3.86G [00:51<00:54, 16.4MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  77% 2.99G/3.86G [00:51<00:36, 24.1MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  78% 3.01G/3.86G [00:52<00:36, 23.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  78% 3.03G/3.86G [00:52<00:25, 32.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  79% 3.05G/3.86G [00:52<00:18, 43.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  79% 3.07G/3.86G [00:52<00:15, 51.7MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  80% 3.09G/3.86G [00:53<00:12, 60.0MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  81% 3.11G/3.86G [00:53<00:10, 74.5MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  81% 3.14G/3.86G [00:53<00:08, 89.1MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  82% 3.16G/3.86G [00:53<00:06, 103MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  82% 3.18G/3.86G [00:53<00:05, 115MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  83% 3.20G/3.86G [00:53<00:05, 127MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  83% 3.22G/3.86G [00:53<00:04, 135MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  84% 3.24G/3.86G [00:54<00:04, 141MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  84% 3.26G/3.86G [00:54<00:04, 148MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  85% 3.28G/3.86G [00:54<00:03, 152MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  85% 3.30G/3.86G [00:54<00:03, 155MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  86% 3.32G/3.86G [00:54<00:03, 150MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  87% 3.34G/3.86G [00:58<00:30, 17.2MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  87% 3.37G/3.86G [00:58<00:21, 23.5MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  88% 3.39G/3.86G [00:58<00:17, 27.1MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  88% 3.40G/3.86G [00:59<00:16, 27.7MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  88% 3.41G/3.86G [00:59<00:16, 27.7MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  88% 3.42G/3.86G [00:59<00:13, 32.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  89% 3.44G/3.86G [00:59<00:08, 47.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90% 3.46G/3.86G [01:00<00:06, 59.9MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90% 3.48G/3.86G [01:00<00:05, 69.9MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90% 3.49G/3.86G [01:00<00:05, 73.9MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91% 3.51G/3.86G [01:00<00:03, 90.6MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91% 3.53G/3.86G [01:00<00:03, 104MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  92% 3.55G/3.86G [01:00<00:02, 117MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  93% 3.58G/3.86G [01:00<00:02, 129MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  93% 3.60G/3.86G [01:01<00:01, 137MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  94% 3.62G/3.86G [01:01<00:01, 130MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  94% 3.64G/3.86G [01:01<00:01, 139MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  95% 3.66G/3.86G [01:01<00:01, 143MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  95% 3.68G/3.86G [01:01<00:01, 147MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  96% 3.70G/3.86G [01:01<00:01, 150MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  96% 3.72G/3.86G [01:01<00:00, 153MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  97% 3.74G/3.86G [01:02<00:00, 151MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  97% 3.76G/3.86G [01:02<00:00, 152MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  98% 3.79G/3.86G [01:02<00:00, 156MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  98% 3.81G/3.86G [01:02<00:00, 94.4MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  99% 3.83G/3.86G [01:02<00:00, 102MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors: 100% 3.85G/3.86G [01:03<00:00, 83.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors: 100% 3.86G/3.86G [01:03<00:00, 60.5MB/s]\n",
            "Downloading shards:  50% 2/4 [03:14<03:03, 91.56s/it] \n",
            "model-00003-of-00004.safetensors:   0% 0.00/3.86G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   0% 10.5M/3.86G [00:01<06:48, 9.43MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   1% 31.5M/3.86G [00:01<02:02, 31.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   1% 52.4M/3.86G [00:01<01:10, 53.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   2% 73.4M/3.86G [00:01<00:50, 74.4MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   2% 94.4M/3.86G [00:01<00:43, 87.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   3% 115M/3.86G [00:01<00:35, 106MB/s]  \u001b[A\n",
            "model-00003-of-00004.safetensors:   4% 136M/3.86G [00:01<00:32, 116MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   4% 157M/3.86G [00:02<00:30, 121MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   5% 178M/3.86G [00:02<00:27, 135MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   5% 199M/3.86G [00:02<00:25, 144MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   6% 220M/3.86G [00:02<00:24, 150MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   6% 241M/3.86G [00:02<00:23, 152MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   7% 262M/3.86G [00:02<00:23, 156MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   7% 283M/3.86G [00:02<00:27, 132MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   8% 304M/3.86G [00:03<00:25, 140MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   8% 325M/3.86G [00:03<00:24, 146MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   9% 346M/3.86G [00:03<00:25, 138MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   9% 367M/3.86G [00:03<00:26, 134MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  10% 388M/3.86G [00:03<00:24, 140MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  11% 409M/3.86G [00:03<00:23, 145MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  11% 430M/3.86G [00:03<00:22, 150MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  12% 451M/3.86G [00:04<00:22, 154MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  12% 472M/3.86G [00:04<00:21, 158MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  13% 493M/3.86G [00:04<00:20, 162MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  13% 514M/3.86G [00:04<00:20, 163MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  14% 535M/3.86G [00:04<00:20, 163MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  14% 556M/3.86G [00:04<00:20, 165MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  15% 577M/3.86G [00:04<00:20, 163MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  15% 598M/3.86G [00:04<00:19, 165MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  16% 619M/3.86G [00:05<00:19, 164MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  17% 640M/3.86G [00:05<00:19, 165MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  17% 661M/3.86G [00:05<00:21, 147MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  18% 682M/3.86G [00:10<04:09, 12.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  18% 703M/3.86G [00:10<02:58, 17.7MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  19% 724M/3.86G [00:10<02:19, 22.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  19% 744M/3.86G [00:11<01:54, 27.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  20% 755M/3.86G [00:11<01:40, 31.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  20% 776M/3.86G [00:11<01:12, 42.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  21% 797M/3.86G [00:11<00:54, 55.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  21% 818M/3.86G [00:11<00:43, 70.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  22% 839M/3.86G [00:11<00:35, 86.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  22% 860M/3.86G [00:12<00:29, 102MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  23% 881M/3.86G [00:12<00:26, 114MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  23% 902M/3.86G [00:12<00:25, 115MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  24% 923M/3.86G [00:12<00:22, 129MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  24% 944M/3.86G [00:12<00:20, 140MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  25% 965M/3.86G [00:12<00:20, 142MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  26% 986M/3.86G [00:12<00:20, 138MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  26% 1.01G/3.86G [00:13<00:19, 147MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  27% 1.03G/3.86G [00:13<00:21, 134MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  27% 1.05G/3.86G [00:18<03:51, 12.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  28% 1.07G/3.86G [00:18<02:45, 16.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  28% 1.09G/3.86G [00:19<02:24, 19.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  29% 1.11G/3.86G [00:19<01:45, 26.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  29% 1.13G/3.86G [00:19<01:17, 35.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  30% 1.15G/3.86G [00:21<01:43, 26.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  30% 1.17G/3.86G [00:21<01:16, 35.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  31% 1.20G/3.86G [00:22<01:31, 29.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  31% 1.21G/3.86G [00:23<02:27, 18.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  31% 1.22G/3.86G [00:24<02:10, 20.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  32% 1.24G/3.86G [00:24<01:29, 29.5MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  33% 1.26G/3.86G [00:24<01:03, 41.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  33% 1.28G/3.86G [00:24<00:47, 55.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  34% 1.30G/3.86G [00:24<00:39, 64.4MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  34% 1.32G/3.86G [00:24<00:31, 80.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  35% 1.34G/3.86G [00:24<00:26, 95.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  35% 1.36G/3.86G [00:25<00:38, 65.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  36% 1.38G/3.86G [00:25<00:30, 80.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  36% 1.41G/3.86G [00:25<00:25, 95.7MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  37% 1.43G/3.86G [00:26<00:31, 78.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  37% 1.45G/3.86G [00:26<00:25, 93.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  38% 1.47G/3.86G [00:26<00:22, 108MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  39% 1.49G/3.86G [00:26<00:38, 62.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  39% 1.51G/3.86G [00:27<00:34, 69.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  40% 1.53G/3.86G [00:27<00:28, 82.5MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  40% 1.55G/3.86G [00:27<00:33, 70.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  40% 1.56G/3.86G [00:27<00:31, 73.4MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  41% 1.58G/3.86G [00:27<00:25, 90.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  42% 1.60G/3.86G [00:28<00:21, 105MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  42% 1.63G/3.86G [00:28<00:44, 50.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  43% 1.65G/3.86G [00:29<00:40, 54.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  43% 1.67G/3.86G [00:29<00:49, 44.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  43% 1.68G/3.86G [00:30<01:14, 29.5MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  44% 1.69G/3.86G [00:31<01:24, 25.7MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  44% 1.71G/3.86G [00:31<00:58, 36.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  45% 1.73G/3.86G [00:31<00:42, 50.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  45% 1.75G/3.86G [00:32<00:41, 51.4MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46% 1.76G/3.86G [00:32<00:36, 56.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46% 1.78G/3.86G [00:32<00:31, 65.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46% 1.79G/3.86G [00:32<00:36, 56.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  47% 1.81G/3.86G [00:32<00:27, 73.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  47% 1.82G/3.86G [00:33<00:46, 44.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48% 1.85G/3.86G [00:33<00:33, 61.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48% 1.87G/3.86G [00:33<00:25, 78.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  49% 1.89G/3.86G [00:33<00:21, 93.7MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  49% 1.91G/3.86G [00:34<00:17, 111MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  50% 1.93G/3.86G [00:34<00:15, 124MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  50% 1.95G/3.86G [00:34<00:14, 134MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  51% 1.97G/3.86G [00:34<00:15, 120MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  52% 1.99G/3.86G [00:34<00:14, 132MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  52% 2.01G/3.86G [00:34<00:12, 143MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  53% 2.03G/3.86G [00:35<00:21, 84.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  53% 2.06G/3.86G [00:35<00:18, 98.5MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  54% 2.08G/3.86G [00:35<00:15, 112MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  54% 2.10G/3.86G [00:36<00:47, 37.5MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  55% 2.11G/3.86G [00:37<01:02, 28.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  55% 2.13G/3.86G [00:37<00:44, 39.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  55% 2.14G/3.86G [00:39<01:31, 18.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  56% 2.16G/3.86G [00:39<01:05, 25.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  56% 2.18G/3.86G [00:39<00:46, 36.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  57% 2.20G/3.86G [00:40<00:34, 48.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  58% 2.22G/3.86G [00:40<00:26, 62.5MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  58% 2.24G/3.86G [00:40<00:20, 77.5MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  59% 2.26G/3.86G [00:40<00:17, 92.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  59% 2.29G/3.86G [00:40<00:14, 106MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  60% 2.31G/3.86G [00:40<00:13, 118MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  60% 2.33G/3.86G [00:40<00:11, 130MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  61% 2.35G/3.86G [00:40<00:10, 138MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  61% 2.37G/3.86G [00:41<00:10, 145MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  62% 2.39G/3.86G [00:41<00:09, 150MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  62% 2.41G/3.86G [00:41<00:09, 152MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  63% 2.43G/3.86G [00:41<00:11, 120MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  63% 2.45G/3.86G [00:41<00:10, 128MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  64% 2.47G/3.86G [00:41<00:10, 138MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  65% 2.50G/3.86G [00:42<00:10, 125MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  65% 2.52G/3.86G [00:45<01:10, 19.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  66% 2.54G/3.86G [00:45<00:51, 25.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  66% 2.56G/3.86G [00:45<00:39, 33.4MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  67% 2.58G/3.86G [00:45<00:31, 40.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  67% 2.60G/3.86G [00:46<00:26, 48.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  68% 2.61G/3.86G [00:46<00:26, 48.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  68% 2.62G/3.86G [00:46<00:26, 47.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  68% 2.64G/3.86G [00:46<00:19, 62.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  69% 2.66G/3.86G [00:46<00:15, 79.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  69% 2.68G/3.86G [00:47<00:12, 95.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  70% 2.71G/3.86G [00:47<00:11, 99.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  71% 2.73G/3.86G [00:47<00:09, 115MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  71% 2.75G/3.86G [00:47<00:08, 125MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  72% 2.77G/3.86G [00:47<00:08, 123MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  72% 2.79G/3.86G [00:47<00:08, 134MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  73% 2.81G/3.86G [00:47<00:07, 143MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  73% 2.83G/3.86G [00:48<00:06, 150MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  74% 2.85G/3.86G [00:48<00:06, 156MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  74% 2.87G/3.86G [00:48<00:06, 161MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  75% 2.89G/3.86G [00:51<00:48, 19.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  75% 2.92G/3.86G [00:51<00:35, 26.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  76% 2.94G/3.86G [00:51<00:25, 36.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  77% 2.96G/3.86G [00:51<00:19, 47.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  77% 2.98G/3.86G [00:52<00:15, 57.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  78% 3.00G/3.86G [00:52<00:12, 72.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  78% 3.02G/3.86G [00:52<00:11, 76.4MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  79% 3.04G/3.86G [00:52<00:11, 74.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  79% 3.06G/3.86G [00:52<00:08, 89.7MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  80% 3.08G/3.86G [00:53<00:11, 70.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  80% 3.10G/3.86G [00:53<00:09, 80.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  81% 3.12G/3.86G [00:53<00:07, 95.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  81% 3.15G/3.86G [00:53<00:06, 110MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  82% 3.17G/3.86G [00:53<00:05, 120MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  82% 3.19G/3.86G [00:54<00:05, 120MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  83% 3.21G/3.86G [00:54<00:05, 131MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  84% 3.23G/3.86G [00:54<00:04, 140MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  84% 3.25G/3.86G [00:56<00:25, 23.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  85% 3.27G/3.86G [00:57<00:24, 24.5MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  85% 3.29G/3.86G [00:57<00:17, 32.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  86% 3.31G/3.86G [00:57<00:12, 43.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  86% 3.33G/3.86G [00:58<00:09, 55.4MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  87% 3.36G/3.86G [00:58<00:07, 68.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  87% 3.38G/3.86G [00:58<00:06, 80.5MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  88% 3.40G/3.86G [00:58<00:04, 95.7MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  88% 3.42G/3.86G [00:58<00:04, 110MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  89% 3.44G/3.86G [00:58<00:03, 116MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  90% 3.46G/3.86G [00:58<00:03, 116MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  90% 3.48G/3.86G [00:59<00:03, 108MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  91% 3.50G/3.86G [00:59<00:02, 121MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  91% 3.52G/3.86G [00:59<00:02, 123MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  92% 3.54G/3.86G [00:59<00:03, 99.7MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  92% 3.57G/3.86G [00:59<00:02, 113MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  93% 3.59G/3.86G [01:00<00:02, 123MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  93% 3.61G/3.86G [01:00<00:01, 134MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  94% 3.63G/3.86G [01:00<00:01, 143MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  94% 3.65G/3.86G [01:00<00:01, 142MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  95% 3.67G/3.86G [01:00<00:01, 149MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  96% 3.69G/3.86G [01:00<00:01, 153MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  96% 3.71G/3.86G [01:00<00:00, 159MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  97% 3.73G/3.86G [01:00<00:00, 163MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  97% 3.75G/3.86G [01:01<00:00, 165MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  98% 3.77G/3.86G [01:01<00:00, 164MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  98% 3.80G/3.86G [01:01<00:00, 164MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  99% 3.82G/3.86G [01:01<00:00, 156MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  99% 3.84G/3.86G [01:01<00:00, 131MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors: 100% 3.86G/3.86G [01:02<00:00, 62.2MB/s]\n",
            "Downloading shards:  75% 3/4 [04:17<01:18, 78.34s/it]\n",
            "model-00004-of-00004.safetensors:   0% 0.00/3.56G [00:00<?, ?B/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   0% 10.5M/3.56G [00:01<06:50, 8.64MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   1% 31.5M/3.56G [00:01<01:59, 29.4MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   1% 52.4M/3.56G [00:01<01:07, 51.8MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   2% 73.4M/3.56G [00:01<00:47, 73.9MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   3% 94.4M/3.56G [00:01<00:41, 83.2MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   3% 115M/3.56G [00:01<00:36, 94.4MB/s] \u001b[A\n",
            "model-00004-of-00004.safetensors:   4% 136M/3.56G [00:02<00:30, 112MB/s] \u001b[A\n",
            "model-00004-of-00004.safetensors:   4% 157M/3.56G [00:02<00:30, 111MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   5% 178M/3.56G [00:02<00:26, 126MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   6% 199M/3.56G [00:02<00:23, 140MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   6% 220M/3.56G [00:02<00:23, 140MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   7% 241M/3.56G [00:02<00:21, 153MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   7% 262M/3.56G [00:02<00:20, 163MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   8% 283M/3.56G [00:02<00:21, 152MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   9% 304M/3.56G [00:03<00:20, 159MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   9% 325M/3.56G [00:03<00:19, 166MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  10% 346M/3.56G [00:03<00:19, 162MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  10% 367M/3.56G [00:03<00:18, 171MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  11% 388M/3.56G [00:03<00:17, 180MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  11% 409M/3.56G [00:03<00:17, 185MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  12% 430M/3.56G [00:03<00:16, 187MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  13% 451M/3.56G [00:03<00:16, 185MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  13% 472M/3.56G [00:04<00:21, 144MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  14% 493M/3.56G [00:18<11:01, 4.63MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  14% 503M/3.56G [00:22<11:45, 4.33MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  15% 524M/3.56G [00:22<07:53, 6.41MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  15% 545M/3.56G [00:22<05:29, 9.13MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  16% 566M/3.56G [00:22<03:49, 13.0MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  17% 587M/3.56G [00:22<02:42, 18.3MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  17% 608M/3.56G [00:22<01:56, 25.3MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  18% 629M/3.56G [00:23<01:36, 30.2MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  18% 650M/3.56G [00:23<01:11, 40.4MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  19% 671M/3.56G [00:23<00:54, 53.1MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  19% 692M/3.56G [00:23<00:43, 65.6MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  20% 713M/3.56G [00:23<00:34, 81.7MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  21% 734M/3.56G [00:23<00:28, 98.1MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  21% 755M/3.56G [00:23<00:27, 103MB/s] \u001b[A\n",
            "model-00004-of-00004.safetensors:  22% 776M/3.56G [00:24<00:23, 118MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  22% 797M/3.56G [00:24<00:20, 132MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  23% 818M/3.56G [00:24<00:20, 135MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  24% 839M/3.56G [00:24<00:18, 148MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  24% 860M/3.56G [00:24<00:17, 158MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  25% 881M/3.56G [00:24<00:17, 153MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  25% 902M/3.56G [00:24<00:16, 163MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  26% 923M/3.56G [00:24<00:15, 169MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  27% 944M/3.56G [00:25<00:15, 172MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  27% 965M/3.56G [00:25<00:15, 171MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  28% 986M/3.56G [00:25<00:14, 174MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  28% 1.01G/3.56G [00:25<00:16, 155MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  29% 1.03G/3.56G [00:25<00:17, 141MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  29% 1.05G/3.56G [00:25<00:16, 152MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  30% 1.07G/3.56G [00:25<00:15, 161MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  31% 1.09G/3.56G [00:26<00:16, 149MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  31% 1.11G/3.56G [00:26<00:16, 148MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  32% 1.13G/3.56G [00:26<00:15, 158MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  32% 1.15G/3.56G [00:26<00:14, 164MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  33% 1.17G/3.56G [00:26<00:21, 112MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  34% 1.20G/3.56G [00:26<00:18, 126MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  34% 1.22G/3.56G [00:27<00:17, 131MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  35% 1.24G/3.56G [00:27<00:17, 136MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  35% 1.26G/3.56G [00:27<00:16, 143MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  36% 1.28G/3.56G [00:27<00:17, 133MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  37% 1.30G/3.56G [00:27<00:15, 145MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  37% 1.32G/3.56G [00:27<00:14, 154MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  38% 1.34G/3.56G [00:27<00:16, 136MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  38% 1.36G/3.56G [00:27<00:14, 147MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  39% 1.38G/3.56G [00:28<00:14, 155MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  40% 1.41G/3.56G [00:28<00:17, 122MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  40% 1.43G/3.56G [00:28<00:19, 111MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  41% 1.45G/3.56G [00:28<00:17, 123MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  41% 1.47G/3.56G [00:28<00:18, 115MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  42% 1.49G/3.56G [00:29<00:16, 127MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  42% 1.51G/3.56G [00:29<00:14, 139MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  43% 1.53G/3.56G [00:29<00:13, 145MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  44% 1.55G/3.56G [00:29<00:13, 151MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  44% 1.57G/3.56G [00:29<00:12, 161MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  45% 1.59G/3.56G [00:29<00:11, 164MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  45% 1.61G/3.56G [00:29<00:11, 164MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  46% 1.64G/3.56G [00:29<00:12, 157MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  47% 1.66G/3.56G [00:30<00:11, 165MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  47% 1.68G/3.56G [00:30<00:14, 127MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  48% 1.70G/3.56G [00:30<00:16, 110MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  48% 1.72G/3.56G [00:30<00:14, 123MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  49% 1.74G/3.56G [00:30<00:13, 137MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  50% 1.76G/3.56G [00:30<00:12, 145MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  50% 1.78G/3.56G [00:31<00:11, 156MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  51% 1.80G/3.56G [00:31<00:11, 154MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  51% 1.82G/3.56G [00:31<00:10, 164MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  52% 1.85G/3.56G [00:31<00:10, 166MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  52% 1.87G/3.56G [00:31<00:10, 161MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  53% 1.89G/3.56G [00:31<00:10, 166MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  54% 1.91G/3.56G [00:31<00:09, 170MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  54% 1.93G/3.56G [00:31<00:09, 177MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  55% 1.95G/3.56G [00:31<00:08, 183MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  55% 1.97G/3.56G [00:32<00:08, 185MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  56% 1.99G/3.56G [00:32<00:08, 175MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  57% 2.01G/3.56G [00:32<00:09, 164MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  57% 2.03G/3.56G [00:32<00:09, 165MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  58% 2.06G/3.56G [00:32<00:08, 172MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  58% 2.08G/3.56G [00:32<00:08, 174MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  59% 2.10G/3.56G [00:32<00:08, 174MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  60% 2.12G/3.56G [00:33<00:08, 162MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  60% 2.14G/3.56G [00:33<00:09, 152MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  61% 2.16G/3.56G [00:33<00:10, 128MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  61% 2.18G/3.56G [00:33<00:10, 136MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  62% 2.20G/3.56G [00:33<00:08, 151MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  63% 2.22G/3.56G [00:33<00:08, 157MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  63% 2.24G/3.56G [00:36<00:49, 26.4MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  64% 2.26G/3.56G [00:37<00:51, 25.1MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  64% 2.28G/3.56G [00:37<00:44, 29.0MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  65% 2.30G/3.56G [00:37<00:31, 40.4MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  65% 2.32G/3.56G [00:37<00:22, 54.2MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  66% 2.34G/3.56G [00:38<00:33, 36.3MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  66% 2.36G/3.56G [00:38<00:24, 48.6MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  67% 2.38G/3.56G [00:38<00:18, 62.7MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  68% 2.40G/3.56G [00:39<00:33, 34.9MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  68% 2.42G/3.56G [00:39<00:25, 45.1MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  69% 2.44G/3.56G [00:40<00:18, 59.0MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  69% 2.46G/3.56G [00:41<00:31, 34.6MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  70% 2.49G/3.56G [00:41<00:24, 44.3MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  70% 2.51G/3.56G [00:41<00:18, 57.7MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  71% 2.53G/3.56G [00:41<00:14, 73.1MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  72% 2.55G/3.56G [00:42<00:22, 45.1MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  72% 2.57G/3.56G [00:44<00:38, 25.6MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  73% 2.58G/3.56G [00:44<00:33, 29.2MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  73% 2.60G/3.56G [00:44<00:32, 29.8MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  74% 2.62G/3.56G [00:45<00:23, 40.1MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  74% 2.63G/3.56G [00:45<00:21, 42.3MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  75% 2.65G/3.56G [00:45<00:15, 57.0MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  75% 2.67G/3.56G [00:45<00:12, 72.7MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  76% 2.69G/3.56G [00:45<00:09, 88.8MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  76% 2.72G/3.56G [00:45<00:07, 108MB/s] \u001b[A\n",
            "model-00004-of-00004.safetensors:  77% 2.74G/3.56G [00:45<00:06, 125MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  78% 2.76G/3.56G [00:45<00:06, 131MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  78% 2.78G/3.56G [00:46<00:05, 145MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  79% 2.80G/3.56G [00:46<00:04, 157MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  79% 2.82G/3.56G [00:46<00:06, 122MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  80% 2.84G/3.56G [00:46<00:05, 138MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  80% 2.86G/3.56G [00:46<00:04, 150MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  81% 2.88G/3.56G [00:46<00:04, 150MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  82% 2.90G/3.56G [00:46<00:04, 160MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  82% 2.93G/3.56G [00:47<00:03, 165MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  83% 2.95G/3.56G [00:47<00:04, 140MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  83% 2.97G/3.56G [00:47<00:04, 147MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  84% 2.99G/3.56G [00:47<00:03, 159MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  85% 3.01G/3.56G [00:47<00:03, 168MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  85% 3.03G/3.56G [00:47<00:03, 171MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  86% 3.05G/3.56G [00:50<00:22, 22.9MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  86% 3.07G/3.56G [00:50<00:16, 30.0MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  87% 3.09G/3.56G [00:51<00:13, 33.2MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  88% 3.11G/3.56G [00:51<00:10, 43.5MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  88% 3.14G/3.56G [00:51<00:07, 55.3MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  89% 3.16G/3.56G [00:51<00:06, 64.8MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  89% 3.18G/3.56G [00:51<00:04, 80.9MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  90% 3.20G/3.56G [00:51<00:03, 98.1MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  91% 3.22G/3.56G [00:51<00:03, 108MB/s] \u001b[A\n",
            "model-00004-of-00004.safetensors:  91% 3.24G/3.56G [00:52<00:02, 121MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  92% 3.26G/3.56G [00:52<00:02, 136MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  92% 3.28G/3.56G [00:52<00:01, 141MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  93% 3.30G/3.56G [00:52<00:01, 152MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  93% 3.32G/3.56G [00:52<00:01, 160MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  94% 3.34G/3.56G [00:52<00:01, 158MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  95% 3.37G/3.56G [00:52<00:01, 166MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  95% 3.39G/3.56G [00:52<00:00, 172MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  96% 3.41G/3.56G [00:53<00:00, 177MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  96% 3.43G/3.56G [00:53<00:00, 162MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  97% 3.45G/3.56G [00:53<00:00, 169MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  98% 3.47G/3.56G [00:53<00:00, 175MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  98% 3.49G/3.56G [00:53<00:00, 165MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  99% 3.51G/3.56G [00:53<00:00, 130MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  99% 3.53G/3.56G [00:54<00:00, 115MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors: 100% 3.56G/3.56G [00:54<00:00, 65.5MB/s]\n",
            "Downloading shards: 100% 4/4 [05:12<00:00, 78.04s/it]\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "Loading checkpoint shards: 100% 4/4 [00:51<00:00, 12.84s/it]\n",
            "generation_config.json: 100% 243/243 [00:00<00:00, 1.50MB/s]\n",
            "Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Model qwen2.5:7b loaded successfully using hf backend (model_id = Qwen/Qwen2.5-7B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [05:00<00:00, 33.33s/it]\n",
            "[INFO]: Running simulation run 2 out of 30\n",
            "Loading checkpoint shards: 100% 4/4 [00:00<00:00,  4.40it/s]\n",
            "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
            "Model qwen2.5:7b loaded successfully using hf backend (model_id = Qwen/Qwen2.5-7B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "  0% 0/9 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "# è¿è¡Œ Qwen 7B ä¸­æ–‡æ¨¡æ‹Ÿ- cant run its too heavy\n",
        "!uv run python src/scripts/alignment_drift/simulate.py --model_name \"qwen2.5:7b\" --prompt_version \"999.0\" --backend hf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f4rXPqECEQvv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNVqK6Fm4vV6hvyShHqwO95",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}