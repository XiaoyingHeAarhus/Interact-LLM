{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XiaoyingHeAarhus/Interact-LLM/blob/main/%E2%80%9C%E6%9C%89%E4%B8%AD%E6%96%87prompt%E7%9A%84%E7%89%88%E6%9C%AC%E2%80%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW_nvUnxDFTC",
        "outputId": "1a3fea6d-a93f-4791-80ab-9d9456411b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Interact-LLM'...\n",
            "remote: Enumerating objects: 636, done.\u001b[K\n",
            "remote: Counting objects: 100% (212/212), done.\u001b[K\n",
            "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
            "remote: Total 636 (delta 126), reused 154 (delta 100), pack-reused 424 (from 1)\u001b[K\n",
            "Receiving objects: 100% (636/636), 177.25 KiB | 1.48 MiB/s, done.\n",
            "Resolving deltas: 100% (295/295), done.\n",
            "/content/Interact-LLM\n",
            "Collecting uv\n",
            "  Downloading uv-0.9.27-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading uv-0.9.27-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.7/22.7 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uv\n",
            "Successfully installed uv-0.9.27\n",
            "\u001b[2mInstalled \u001b[1mPython 3.12.12\u001b[0m \u001b[2min 2.58s\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcpython-3.12.12-linux-x86_64-gnu\u001b[0m (python3.12)\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`\u001b[36m/root/.local/bin\u001b[39m` is not on your PATH. To use installed Python executables, run `\u001b[32mexport PATH=\"/root/.local/bin:$PATH\"\u001b[39m` or `\u001b[32muv python update-shell\u001b[39m`.\u001b[0m\n",
            "Using CPython \u001b[36m3.12.12\u001b[39m\u001b[36m\u001b[39m\n",
            "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
            "\u001b[2mResolved \u001b[1m63 packages\u001b[0m \u001b[2min 0.93ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m62 packages\u001b[0m \u001b[2min 1m 25s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m62 packages\u001b[0m \u001b[2min 493ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.5.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.1.31\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.18.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.29.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1minteract-llm\u001b[0m\u001b[2m==0.1.0 (from file:///content/Interact-LLM)\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlingua-language-detector\u001b[0m\u001b[2m==2.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlinkify-it-py\u001b[0m\u001b[2m==2.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmdit-py-plugins\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmlx\u001b[0m\u001b[2m==0.23.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmlx-lm\u001b[0m\u001b[2m==0.21.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.2.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.4.5.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.1.0.70\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.5.147\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.1.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.3.1.170\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.21.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==24.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.3.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.30.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.10.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.27.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2024.11.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==13.9.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mruff\u001b[0m\u001b[2m==0.11.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.5.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msentencepiece\u001b[0m\u001b[2m==0.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==76.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtextual\u001b[0m\u001b[2m==2.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtoml\u001b[0m\u001b[2m==0.10.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.21.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.50.0.dev0 (from git+https://github.com/huggingface/transformers@46350f5eae87ac1d168ddfdc57a0b39b64b9a029)\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.12.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1muc-micro-py\u001b[0m\u001b[2m==1.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.3.0\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 1. å…‹éš†ä»£ç \n",
        "!git clone https://github.com/XiaoyingHeAarhus/Interact-LLM.git\n",
        "%cd Interact-LLM\n",
        "\n",
        "# 2. å®‰è£… uv å’Œä¾èµ–\n",
        "!pip install uv\n",
        "# å¼ºåˆ¶ä½¿ç”¨ Python 3.12 å¹¶åˆ æ‰æ²¡ç”¨çš„ mlx (Colab é»˜è®¤æ˜¯ 3.11+)\n",
        "!uv python install 3.12\n",
        "!uv sync --python 3.12"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 1. è¿›å…¥é¡¹ç›®ç›®å½•\n",
        "%cd /content/Interact-LLM\n",
        "\n",
        "# 2. è‡ªåŠ¨åŒ–è¿è¡Œ 30 è½®çš„ Python é€»è¾‘\n",
        "# æˆ‘ä»¬é€šè¿‡å¾ªç¯è°ƒç”¨æ¥ç¡®ä¿ä»»åŠ¡çš„ç‹¬ç«‹æ€§\n",
        "for i in range(1, 31):\n",
        "    print(f\"ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ {i} è½®å®éªŒ (Total: 30)...\")\n",
        "\n",
        "    # ä½¿ç”¨ NO_COLOR=1 ä¿æŒæ—¥å¿—æ•´æ´\n",
        "    # ä½¿ç”¨ 1.5B æ¨¡å‹ä»¥ç¡®ä¿åœ¨ Colab T4 æ˜¾å­˜ä¸­ç¨³å®šè¿è¡Œ\n",
        "    # ç¡®ä¿ prompt_version å¯¹åº”ä½ é‡å‘½ååçš„ v999.0.toml\n",
        "    !NO_COLOR=1 uv run python src/scripts/alignment_drift/simulate.py \\\n",
        "        --model_name \"Qwen/Qwen2.5-1.5B-Instruct\" \\\n",
        "        --prompt_version \"999\" \\\n",
        "        --backend hf\n",
        "\n",
        "    print(f\"âœ… ç¬¬ {i} è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\")\n",
        "\n",
        "print(\"ğŸŠ æ­å–œï¼30 è½®ä¸­æ–‡å¯¹è¯æ¨¡æ‹Ÿå…¨éƒ¨è¿è¡Œå®Œæ¯•ï¼\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UORJcjWO_L_i",
        "outputId": "77258483-01e1-4ccd-80c8-62efd864db6e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Interact-LLM\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 1 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 1 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 2 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 2 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 3 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 3 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 4 è½®å®éªŒ (Total: 30)...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 14, in <module>\n",
            "    from interact_llm.llm.hf_wrapper import ChatHF\n",
            "  File \"/content/Interact-LLM/src/interact_llm/llm/hf_wrapper.py\", line 8, in <module>\n",
            "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
            "  File \"<frozen importlib._bootstrap>\", line 1412, in _handle_fromlist\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1874, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1873, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1885, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/models/auto/modeling_auto.py\", line 21, in <module>\n",
            "    from .auto_factory import (\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py\", line 40, in <module>\n",
            "    from ...generation import GenerationMixin\n",
            "  File \"<frozen importlib._bootstrap>\", line 1412, in _handle_fromlist\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1873, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1885, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/generation/utils.py\", line 29, in <module>\n",
            "    from transformers.generation.candidate_generator import AssistantVocabTranslatorCache\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/generation/candidate_generator.py\", line 30, in <module>\n",
            "    from ..pytorch_utils import isin_mps_friendly\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py\", line 49, in <module>\n",
            "    from torch.distributed.tensor.parallel import (\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/__init__.py\", line 2, in <module>\n",
            "    from torch.distributed.tensor.parallel.api import parallelize_module\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/api.py\", line 9, in <module>\n",
            "    from torch.distributed.tensor.parallel._utils import _validate_tp_mesh_dim\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/_utils.py\", line 11, in <module>\n",
            "    from torch._dynamo.external_utils import is_compiling as is_torchdynamo_compiling\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/_dynamo/__init__.py\", line 3, in <module>\n",
            "    from . import convert_frame, eval_frame, resume_execution\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 33, in <module>\n",
            "    from torch._dynamo.symbolic_convert import TensorifyState\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 27, in <module>\n",
            "    from torch._dynamo.exc import TensorifyScalarRestartAnalysis\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/_dynamo/exc.py\", line 11, in <module>\n",
            "    from .utils import counters\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py\", line 66, in <module>\n",
            "    import torch.fx.experimental.symbolic_shapes\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 64, in <module>\n",
            "    from torch.fx.experimental.recording import (\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/fx/experimental/recording.py\", line 345, in <module>\n",
            "    @dataclass\n",
            "     ^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/dataclasses.py\", line 1275, in dataclass\n",
            "    return wrap(cls)\n",
            "           ^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/dataclasses.py\", line 1265, in wrap\n",
            "    return _process_class(cls, init, repr, eq, order, unsafe_hash,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/dataclasses.py\", line 1063, in _process_class\n",
            "    _init_fn(all_init_fields,\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/dataclasses.py\", line 588, in _init_fn\n",
            "    locals = {f'__dataclass_type_{f.name}__': f.type for f in fields}\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "âœ… ç¬¬ 4 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 5 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 5 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 6 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 6 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 7 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 7 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 8 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 8 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 9 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 9 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 10 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 10 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 11 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 11 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 12 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 12 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 13 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 13 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 14 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 14 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 15 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 15 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 16 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 16 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 17 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 17 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 18 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 18 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 19 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 19 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 20 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 20 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 21 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 21 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 22 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 22 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 23 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 23 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 24 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 24 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 25 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 90, in load_model_backend\n",
            "    model_id = get_model_id(\n",
            "               ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 46, in get_model_id\n",
            "    raise ValueError(\n",
            "ValueError: No model defined for 'Qwen/Qwen2.5-1.5B-Instruct. Add it to 'models.toml' or choose between defined models: ['qwen2.5:7b', 'llama3.1:8b', 'gemma3:12b', 'mistral:7b']'\n",
            "âœ… ç¬¬ 25 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 26 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "tokenizer_config.json: 7.30kB [00:00, 37.7MB/s]\n",
            "vocab.json: 2.78MB [00:00, 70.6MB/s]\n",
            "merges.txt: 1.67MB [00:00, 141MB/s]\n",
            "tokenizer.json: 7.03MB [00:00, 187MB/s]\n",
            "config.json: 100% 660/660 [00:00<00:00, 5.03MB/s]\n",
            "model.safetensors:   2% 73.4M/3.09G [00:30<20:35, 2.44MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 109, in load_model_backend\n",
            "    model.load()\n",
            "  File \"/content/Interact-LLM/src/interact_llm/llm/hf_wrapper.py\", line 44, in load\n",
            "    self.model = AutoModelForCausalLM.from_pretrained(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 273, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 3998, in from_pretrained\n",
            "    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/hub.py\", line 342, in cached_file\n",
            "    resolved_file = hf_hub_download(\n",
            "                    ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 862, in hf_hub_download\n",
            "    return _hf_hub_download_to_cache_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 1011, in _hf_hub_download_to_cache_dir\n",
            "    _download_to_tmp_and_move(\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 1547, in _download_to_tmp_and_move\n",
            "    http_get(\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 454, in http_get\n",
            "    for chunk in r.iter_content(chunk_size=constants.DOWNLOAD_CHUNK_SIZE):\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/requests/models.py\", line 820, in generate\n",
            "    yield from self.raw.stream(chunk_size, decode_content=True)\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/urllib3/response.py\", line 1066, in stream\n",
            "    data = self.read(amt=amt, decode_content=decode_content)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/urllib3/response.py\", line 955, in read\n",
            "    data = self._raw_read(amt)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/urllib3/response.py\", line 879, in _raw_read\n",
            "    data = self._fp_read(amt, read1=read1) if not fp_closed else b\"\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/urllib3/response.py\", line 862, in _fp_read\n",
            "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/http/client.py\", line 479, in read\n",
            "    s = self.fp.read(amt)\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/socket.py\", line 720, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/ssl.py\", line 1251, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/ssl.py\", line 1103, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "âœ… ç¬¬ 26 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 27 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "model.safetensors: 100% 3.09G/3.09G [02:28<00:00, 20.2MB/s]\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "generation_config.json: 100% 242/242 [00:00<00:00, 1.38MB/s]\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [00:52<00:00,  5.84s/it]\n",
            "[INFO]: Running simulation run 2 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [01:55<00:00, 12.80s/it]\n",
            "[INFO]: Running simulation run 3 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [00:43<00:00,  4.81s/it]\n",
            "[INFO]: Running simulation run 4 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [02:07<00:00, 14.15s/it]\n",
            "[INFO]: Running simulation run 5 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [00:50<00:00,  5.67s/it]\n",
            "[INFO]: Running simulation run 6 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [00:50<00:00,  5.65s/it]\n",
            "[INFO]: Running simulation run 7 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [00:44<00:00,  4.94s/it]\n",
            "[INFO]: Running simulation run 8 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            " 89% 8/9 [01:29<00:11, 11.13s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 177, in main\n",
            "    tutor_history = simulate_conversation(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 100, in simulate_conversation\n",
            "    tutor_message = model.generate(tutor_history)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/llm/hf_wrapper.py\", line 92, in generate\n",
            "    output = self.model.generate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/generation/utils.py\", line 2250, in generate\n",
            "    result = self._sample(\n",
            "             ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/generation/utils.py\", line 3241, in _sample\n",
            "    outputs = model_forward(**model_inputs, return_dict=True)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py\", line 855, in forward\n",
            "    outputs = self.model(\n",
            "              ^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py\", line 579, in forward\n",
            "    layer_outputs = decoder_layer(\n",
            "                    ^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py\", line 275, in forward\n",
            "    hidden_states = self.post_attention_layernorm(hidden_states)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py\", line 221, in forward\n",
            "    variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "âœ… ç¬¬ 27 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 28 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [00:24<00:00,  2.67s/it]\n",
            "[INFO]: Running simulation run 2 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [00:56<00:00,  6.24s/it]\n",
            "[INFO]: Running simulation run 3 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [02:52<00:00, 19.18s/it]\n",
            "[INFO]: Running simulation run 4 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [01:26<00:00,  9.63s/it]\n",
            "[INFO]: Running simulation run 5 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [01:13<00:00,  8.18s/it]\n",
            "[INFO]: Running simulation run 6 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [00:59<00:00,  6.57s/it]\n",
            "[INFO]: Running simulation run 7 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [01:20<00:00,  8.91s/it]\n",
            "[INFO]: Running simulation run 8 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [00:31<00:00,  3.54s/it]\n",
            "[INFO]: Running simulation run 9 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [01:00<00:00,  6.77s/it]\n",
            "[INFO]: Running simulation run 10 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [02:12<00:00, 14.68s/it]\n",
            "[INFO]: Running simulation run 11 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [00:57<00:00,  6.34s/it]\n",
            "[INFO]: Running simulation run 12 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [00:31<00:00,  3.51s/it]\n",
            "[INFO]: Running simulation run 13 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [00:45<00:00,  5.02s/it]\n",
            "[INFO]: Running simulation run 14 out of 30\n",
            "Model Qwen/Qwen2.5-1.5B-Instruct loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            " 89% 8/9 [00:49<00:06,  6.19s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 177, in main\n",
            "    tutor_history = simulate_conversation(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 100, in simulate_conversation\n",
            "    tutor_message = model.generate(tutor_history)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/llm/hf_wrapper.py\", line 92, in generate\n",
            "    output = self.model.generate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/generation/utils.py\", line 2250, in generate\n",
            "    result = self._sample(\n",
            "             ^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/generation/utils.py\", line 3241, in _sample\n",
            "    outputs = model_forward(**model_inputs, return_dict=True)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py\", line 855, in forward\n",
            "    outputs = self.model(\n",
            "              ^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py\", line 579, in forward\n",
            "    layer_outputs = decoder_layer(\n",
            "                    ^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py\", line 260, in forward\n",
            "    hidden_states, self_attn_weights = self.self_attn(\n",
            "                                       ^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py\", line 192, in forward\n",
            "    attn_output, attn_weights = attention_interface(\n",
            "                                ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/integrations/sdpa_attention.py\", line 54, in sdpa_attention_forward\n",
            "    attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "âœ… ç¬¬ 28 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 29 è½®å®éªŒ (Total: 30)...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 211, in <module>\n",
            "    main()\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 148, in main\n",
            "    model = load_model_backend(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/src/interact_llm/utils/model_load.py\", line 109, in load_model_backend\n",
            "    model.load()\n",
            "  File \"/content/Interact-LLM/src/interact_llm/llm/hf_wrapper.py\", line 44, in load\n",
            "    self.model = AutoModelForCausalLM.from_pretrained(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 273, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 4451, in from_pretrained\n",
            "    ) = cls._load_pretrained_model(\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 5024, in _load_pretrained_model\n",
            "    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(\n",
            "                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 896, in _load_state_dict_into_meta_model\n",
            "    param = param.to(param_casting_dtype)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "âœ… ç¬¬ 29 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 30 è½®å®éªŒ (Total: 30)...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Interact-LLM/src/scripts/alignment_drift/simulate.py\", line 14, in <module>\n",
            "    from interact_llm.llm.hf_wrapper import ChatHF\n",
            "  File \"/content/Interact-LLM/src/interact_llm/llm/hf_wrapper.py\", line 8, in <module>\n",
            "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
            "  File \"<frozen importlib._bootstrap>\", line 1412, in _handle_fromlist\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1873, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1885, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/models/__init__.py\", line 15, in <module>\n",
            "    from . import (\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/models/mobilevit/__init__.py\", line 30, in <module>\n",
            "    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)\n",
            "                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 2309, in define_import_structure\n",
            "    import_structure = create_import_structure_from_path(module_path)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 2178, in create_import_structure_from_path\n",
            "    for _all_object in fetch__all__(file_content):\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Interact-LLM/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1960, in fetch__all__\n",
            "    if line.startswith(\"__all__\"):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "âœ… ç¬¬ 30 è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\n",
            "ğŸŠ æ­å–œï¼30 è½®ä¸­æ–‡å¯¹è¯æ¨¡æ‹Ÿå…¨éƒ¨è¿è¡Œå®Œæ¯•ï¼\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Interact-LLM\n",
        "\n",
        "for i in range(1, 31):\n",
        "    print(f\"ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ {i} è½®å®éªŒ...\")\n",
        "    # æ³¨æ„è¿™é‡Œä½¿ç”¨çš„æ˜¯ name å®šä¹‰çš„ç®€ç§° qwen25_15b\n",
        "    !NO_COLOR=1 uv run python src/scripts/alignment_drift/simulate.py \\\n",
        "        --model_name \"qwen25_15b\" \\\n",
        "        --prompt_version \"999\" \\\n",
        "        --backend hf\n",
        "    print(f\"âœ… ç¬¬ {i} è½®å®éªŒå·²å®Œæˆå¹¶ä¿å­˜ç»“æœã€‚\")\n",
        "\n",
        "print(\"ğŸŠ æ­å–œï¼30 è½®ä¸­æ–‡å¯¹è¯æ¨¡æ‹Ÿå…¨éƒ¨è¿è¡Œå®Œæ¯•ï¼\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ik6G47gA2GS",
        "outputId": "463a5262-59be-41d5-eb8a-433c8ada092c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Interact-LLM\n",
            "ğŸš€ æ­£åœ¨å¯åŠ¨ç¬¬ 1 è½®å®éªŒ...\n",
            "[INFO]: Running simulation run 1 out of 30\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "Model qwen25_15b loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [01:17<00:00,  8.63s/it]\n",
            "[INFO]: Running simulation run 2 out of 30\n",
            "Model qwen25_15b loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [01:01<00:00,  6.84s/it]\n",
            "[INFO]: Running simulation run 3 out of 30\n",
            "Model qwen25_15b loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [00:33<00:00,  3.77s/it]\n",
            "[INFO]: Running simulation run 4 out of 30\n",
            "Model qwen25_15b loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [00:34<00:00,  3.83s/it]\n",
            "[INFO]: Running simulation run 5 out of 30\n",
            "Model qwen25_15b loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [00:16<00:00,  1.87s/it]\n",
            "[INFO]: Running simulation run 6 out of 30\n",
            "Model qwen25_15b loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            "100% 9/9 [01:07<00:00,  7.46s/it]\n",
            "[INFO]: Running simulation run 7 out of 30\n",
            "Model qwen25_15b loaded successfully using hf backend (model_id = Qwen/Qwen2.5-1.5B-Instruct)\n",
            "[INFO]: Formatting prompts using toml file version 999.0 and prompt id A1\n",
            " 78% 7/9 [01:12<00:23, 11.55s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f4rXPqECEQvv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyP9M1RDjwaHmc9fPJ6mKw0/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}